{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4:  Wrangle and Analyze Data \n",
    "### By Mirna Slim\n",
    "#### The project's objective is to practice the 3 phases of data wrangling: gather, assess, and clean. \n",
    "\n",
    "## Data Set: WeRateDogs\n",
    "\n",
    "#### The dataset used, wrangled, analyzed, and vicsualized is the tweet archive of Twitter user @dog_rates - also known as WeRateDogs - that rates people's dogs with a humorous comment about the dog. \n",
    "#### (Data files provided by Udacity will be used as a request to have a Twitter developer accpunt was denied)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sections of the Report:\n",
    " \n",
    "•\tModules Imported\n",
    "•\tData Source  \n",
    "•\tGathering Data\n",
    "•\tAssessing data  \n",
    "•\tCleaning data  \n",
    "•\tStoring, analyzing, and visualizing wrangled data  \n",
    "•\tReporting on 1) your data wrangling efforts and 2) your data analyses and visualizations  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imported Modules\n",
    "\n",
    "The following modules were imported to be used.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install wptools;\n",
    "#!pip install tweepy;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all packages and set plots to be embedded inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import wptools\n",
    "import os\n",
    "import requests\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import json\n",
    "from timeit import default_timer as timer\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering Data\n",
    "\n",
    "Request to get a Twitter Developer account was denied (despite using the language that Udacity provides), the Udacity Python code ('twitter_api.py') was used to access/gather data. The data files ('tweet_json.txt','twitter-archive-enhanced.csv', and 'image-predictions.tsv') built/provided by Udacity are used.  \n",
    "There are 3 main data files that need to be gathered: \n",
    "\n",
    "### 1- The Enhanced Twitter Archive  \n",
    "This file is provided by Udacity. It contains the WeRateDogs Twitter archive which consists of basic tweet data (not everything!) for 5000+ tweets. Udacity used the text column to extract:\n",
    "- Tweet ID  \n",
    "- dog name  \n",
    "- dog rating    \n",
    "- and dog \"stage\" (i.e. doggo, floofer, pupper, and puppo). \n",
    "\n",
    "The Enhanved Twitter Archive is prepared, by Udacity, from the JSON .txt file containing Twitter archive of the 5000+ tweets leaving only entries with ratings. A total of 2356 records/entries exist in the Enhanved Twitter Archive file. \n",
    "\n",
    "### 2- JSON.txt file\n",
    "Ideally, the following steps would have been done to construct the JSON:  \n",
    "1- Use tweet IDs in the WeRateDogs Twitter archive to query the Twitter API for each tweet's JSON data using Python's Tweepy library,   \n",
    "2- Store each tweet's entire set of JSON data in a file called tweet_json.txt file (each tweet's JSON data should be written to its own line in a loop).  \n",
    "3- Read the JSON file into a pandas DataFrame containing, at minimum, tweet ID, retweet count, and favorite count. \n",
    "\n",
    "### 3- The 'Iimage-prediction.tsv\" file\n",
    "The file contains image URLs and dog breed predictions of the various dogs in the archinve. A Neural Network was used. This file (image_predictions.tsv) is hosted on Udacity's servers and was downloaded programmatically using the Requests library \n",
    "Enhanced Twitter Archive\n",
    "\n",
    "- p1 is the algorithm's #1 prediction for the image in the tweet.\n",
    "- p2 and p3 are the algorithm's second and third most likely predictions.  \n",
    "- p#_conf is how confident the algorithm is in each corresponding prediction. \n",
    "- p#_dog is whether or not the # prediction is a breed of dog → TRUE or FALSE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following 3 cells are provided by Udacity as a Python code to access data if one has no Twitter API account. They are added in this notebook for completness. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Twitter API for each tweet in the Twitter archive and save JSON in a text file\n",
    "# These are hidden to comply with Twitter's API terms and conditions\n",
    "consumer_key = 'HIDDEN'\n",
    "consumer_secret = 'HIDDEN'\n",
    "access_token = 'HIDDEN'\n",
    "access_secret = 'HIDDEN'\n",
    "\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE TO STUDENT WITH MOBILE VERIFICATION ISSUES:\n",
    "# df_1 is a DataFrame with the twitter_archive_enhanced.csv file. You may have to\n",
    "# change line 17 to match the name of your DataFrame with twitter_archive_enhanced.csv\n",
    "# NOTE TO REVIEWER: this student had mobile verification issues so the following\n",
    "# Twitter API code was sent to this student from a Udacity instructor\n",
    "# Tweet IDs for which to gather additional data via Twitter's API\n",
    "tweet_ids = df_1.tweet_id.values\n",
    "len(tweet_ids)\n",
    "\n",
    "# Query Twitter's API for JSON data for each tweet ID in the Twitter archive\n",
    "count = 0\n",
    "fails_dict = {}\n",
    "start = timer()\n",
    "# Save each tweet's returned JSON as a new line in a .txt file\n",
    "with open('tweet_json.txt', 'w') as outfile:\n",
    "    # This loop will likely take 20-30 minutes to run because of Twitter's rate limit\n",
    "    for tweet_id in tweet_ids:\n",
    "        count += 1\n",
    "        print(str(count) + \": \" + str(tweet_id))\n",
    "        try:\n",
    "            tweet = api.get_status(tweet_id, tweet_mode='extended')\n",
    "            print(\"Success\")\n",
    "            json.dump(tweet._json, outfile)\n",
    "            outfile.write('\\n')\n",
    "        except tweepy.TweepError as e:\n",
    "            print(\"Fail\")\n",
    "            fails_dict[tweet_id] = e\n",
    "            pass\n",
    "end = timer()\n",
    "print(end - start)\n",
    "print(fails_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Data Gathering  \n",
    "\n",
    "#### 1- The Enhanced Twitter Archive is used as provided.  \n",
    "#### 2- The JSON .txt file is used as provided by Udacity (no need to build it from scratch).  \n",
    "(refrence to learn how to extract tweets using tweepy: https://fairyonice.github.io/extract-someones-tweet-using-tweepy.html)\n",
    "#### 3- The Image prediction file was imported and saved as a tsv file as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# downloading the tweet image-prediction file programmatically\n",
    "url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "response = requests.get(url)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "path = 'C:/Users/Mirna.Slim/UdacityCurrent/Project4'\n",
    "with open(os.path.join(path,\n",
    "                       url.split('/')[-1]), mode='wb') as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==============================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Data Files and Save to Dataframes  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the \"Enhanced_twitter_Archive\"\n",
    "archive = pd.read_csv('twitter-archive-enhanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892420643555336193</td>\n",
       "      <td>39467</td>\n",
       "      <td>8853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id  favorite_count  retweet_count\n",
       "0  892420643555336193           39467           8853"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the tweet_json.txt file:\n",
    "with open('tweet_json.txt', 'r') as f:\n",
    "    tweet_json = pd.read_json(f, lines=True)\n",
    "tweet_json = tweet_json[['id','favorite_count','retweet_count']]\n",
    "tweet_json.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_prediction = pd.read_csv('image-predictions.tsv', sep='\\t' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "      <th>retweeted_status_user_id</th>\n",
       "      <th>retweeted_status_timestamp</th>\n",
       "      <th>expanded_urls</th>\n",
       "      <th>rating_numerator</th>\n",
       "      <th>rating_denominator</th>\n",
       "      <th>name</th>\n",
       "      <th>doggo</th>\n",
       "      <th>floofer</th>\n",
       "      <th>pupper</th>\n",
       "      <th>puppo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.924210e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-01 16:23:56 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Phineas. He's a mystical boy. Only eve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/892420643...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Phineas</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id  in_reply_to_status_id  in_reply_to_user_id  \\\n",
       "0  8.924210e+17                    NaN                  NaN   \n",
       "\n",
       "                   timestamp  \\\n",
       "0  2017-08-01 16:23:56 +0000   \n",
       "\n",
       "                                              source  \\\n",
       "0  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "\n",
       "                                                text  retweeted_status_id  \\\n",
       "0  This is Phineas. He's a mystical boy. Only eve...                  NaN   \n",
       "\n",
       "   retweeted_status_user_id retweeted_status_timestamp  \\\n",
       "0                       NaN                        NaN   \n",
       "\n",
       "                                       expanded_urls  rating_numerator  \\\n",
       "0  https://twitter.com/dog_rates/status/892420643...                13   \n",
       "\n",
       "   rating_denominator     name doggo floofer pupper puppo  \n",
       "0                  10  Phineas  None    None   None  None  "
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing Data\n",
    "After gathering each of the above data files and open them as dataframes, the data is assessed visually and programmatically for quality and tidiness issues.  \n",
    "\n",
    "### Visually  \n",
    "Each data file can be opened and the various series, series' headers, data/entries can be inspected. A summary of the issues identified is provided below. \n",
    "\n",
    "### Programmatically\n",
    "Inspectiion and data assessment is also done programmatically using functions like:\n",
    "- .info(), .describe(): to give summaries of the data/series in the datasets.  \n",
    "- .isnull().sum(): to check for missing data.  \n",
    "- .duplicate(), .series.value_counts(): to see if entries belonging to the the same tweet ID are duplicated.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programmatic Assessment of Enhanced Archive Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2356 entries, 0 to 2355\n",
      "Data columns (total 17 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   tweet_id                    2356 non-null   float64\n",
      " 1   in_reply_to_status_id       78 non-null     float64\n",
      " 2   in_reply_to_user_id         78 non-null     float64\n",
      " 3   timestamp                   2356 non-null   object \n",
      " 4   source                      2356 non-null   object \n",
      " 5   text                        2356 non-null   object \n",
      " 6   retweeted_status_id         181 non-null    float64\n",
      " 7   retweeted_status_user_id    181 non-null    float64\n",
      " 8   retweeted_status_timestamp  181 non-null    object \n",
      " 9   expanded_urls               2297 non-null   object \n",
      " 10  rating_numerator            2356 non-null   int64  \n",
      " 11  rating_denominator          2356 non-null   int64  \n",
      " 12  name                        2356 non-null   object \n",
      " 13  doggo                       2356 non-null   object \n",
      " 14  floofer                     2356 non-null   object \n",
      " 15  pupper                      2356 non-null   object \n",
      " 16  puppo                       2356 non-null   object \n",
      "dtypes: float64(5), int64(2), object(10)\n",
      "memory usage: 313.0+ KB\n"
     ]
    }
   ],
   "source": [
    "archive.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "      <th>retweeted_status_user_id</th>\n",
       "      <th>rating_numerator</th>\n",
       "      <th>rating_denominator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.356000e+03</td>\n",
       "      <td>7.800000e+01</td>\n",
       "      <td>7.800000e+01</td>\n",
       "      <td>1.810000e+02</td>\n",
       "      <td>1.810000e+02</td>\n",
       "      <td>2356.000000</td>\n",
       "      <td>2356.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.427716e+17</td>\n",
       "      <td>7.455128e+17</td>\n",
       "      <td>2.015385e+16</td>\n",
       "      <td>7.720221e+17</td>\n",
       "      <td>1.241437e+16</td>\n",
       "      <td>13.126486</td>\n",
       "      <td>10.455433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.856706e+16</td>\n",
       "      <td>7.583419e+16</td>\n",
       "      <td>1.253546e+17</td>\n",
       "      <td>6.236131e+16</td>\n",
       "      <td>9.597227e+16</td>\n",
       "      <td>45.876648</td>\n",
       "      <td>6.745237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.660210e+17</td>\n",
       "      <td>6.660000e+17</td>\n",
       "      <td>1.185634e+07</td>\n",
       "      <td>6.660000e+17</td>\n",
       "      <td>7.832140e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.783992e+17</td>\n",
       "      <td>6.760000e+17</td>\n",
       "      <td>3.086374e+08</td>\n",
       "      <td>7.190000e+17</td>\n",
       "      <td>4.196984e+09</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.196275e+17</td>\n",
       "      <td>7.035000e+17</td>\n",
       "      <td>4.196984e+09</td>\n",
       "      <td>7.800000e+17</td>\n",
       "      <td>4.196984e+09</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.993375e+17</td>\n",
       "      <td>8.260000e+17</td>\n",
       "      <td>4.196984e+09</td>\n",
       "      <td>8.200000e+17</td>\n",
       "      <td>4.196984e+09</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.924210e+17</td>\n",
       "      <td>8.860000e+17</td>\n",
       "      <td>8.410000e+17</td>\n",
       "      <td>8.870000e+17</td>\n",
       "      <td>7.870000e+17</td>\n",
       "      <td>1776.000000</td>\n",
       "      <td>170.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tweet_id  in_reply_to_status_id  in_reply_to_user_id  \\\n",
       "count  2.356000e+03           7.800000e+01         7.800000e+01   \n",
       "mean   7.427716e+17           7.455128e+17         2.015385e+16   \n",
       "std    6.856706e+16           7.583419e+16         1.253546e+17   \n",
       "min    6.660210e+17           6.660000e+17         1.185634e+07   \n",
       "25%    6.783992e+17           6.760000e+17         3.086374e+08   \n",
       "50%    7.196275e+17           7.035000e+17         4.196984e+09   \n",
       "75%    7.993375e+17           8.260000e+17         4.196984e+09   \n",
       "max    8.924210e+17           8.860000e+17         8.410000e+17   \n",
       "\n",
       "       retweeted_status_id  retweeted_status_user_id  rating_numerator  \\\n",
       "count         1.810000e+02              1.810000e+02       2356.000000   \n",
       "mean          7.720221e+17              1.241437e+16         13.126486   \n",
       "std           6.236131e+16              9.597227e+16         45.876648   \n",
       "min           6.660000e+17              7.832140e+05          0.000000   \n",
       "25%           7.190000e+17              4.196984e+09         10.000000   \n",
       "50%           7.800000e+17              4.196984e+09         11.000000   \n",
       "75%           8.200000e+17              4.196984e+09         12.000000   \n",
       "max           8.870000e+17              7.870000e+17       1776.000000   \n",
       "\n",
       "       rating_denominator  \n",
       "count         2356.000000  \n",
       "mean            10.455433  \n",
       "std              6.745237  \n",
       "min              0.000000  \n",
       "25%             10.000000  \n",
       "50%             10.000000  \n",
       "75%             10.000000  \n",
       "max            170.000000  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for entry duplications\n",
    "archive.tweet_id.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.757070e+17    2\n",
       "8.322160e+17    2\n",
       "6.737160e+17    2\n",
       "6.747430e+17    2\n",
       "6.751470e+17    2\n",
       "6.675510e+17    2\n",
       "8.190150e+17    2\n",
       "7.276860e+17    1\n",
       "8.347860e+17    1\n",
       "8.703090e+17    1\n",
       "Name: tweet_id, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive.tweet_id.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                         0\n",
       "in_reply_to_status_id         2278\n",
       "in_reply_to_user_id           2278\n",
       "timestamp                        0\n",
       "source                           0\n",
       "text                             0\n",
       "retweeted_status_id           2175\n",
       "retweeted_status_user_id      2175\n",
       "retweeted_status_timestamp    2175\n",
       "expanded_urls                   59\n",
       "rating_numerator                 0\n",
       "rating_denominator               0\n",
       "name                             0\n",
       "doggo                            0\n",
       "floofer                          0\n",
       "pupper                           0\n",
       "puppo                            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing data/entries\n",
    "archive.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "315        0\n",
       "1016       0\n",
       "2335       1\n",
       "2261       1\n",
       "2338       1\n",
       "        ... \n",
       "2074     420\n",
       "188      420\n",
       "189      666\n",
       "313      960\n",
       "979     1776\n",
       "Name: rating_numerator, Length: 2356, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive.rating_numerator.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programmatic Assessment of tweet_json Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2354 entries, 0 to 2353\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype\n",
      "---  ------          --------------  -----\n",
      " 0   id              2354 non-null   int64\n",
      " 1   favorite_count  2354 non-null   int64\n",
      " 2   retweet_count   2354 non-null   int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 55.3 KB\n"
     ]
    }
   ],
   "source": [
    "tweet_json.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.354000e+03</td>\n",
       "      <td>2354.000000</td>\n",
       "      <td>2354.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.426978e+17</td>\n",
       "      <td>8080.968564</td>\n",
       "      <td>3164.797366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.852812e+16</td>\n",
       "      <td>11814.771334</td>\n",
       "      <td>5284.770364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.660209e+17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.783975e+17</td>\n",
       "      <td>1415.000000</td>\n",
       "      <td>624.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.194596e+17</td>\n",
       "      <td>3603.500000</td>\n",
       "      <td>1473.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.993058e+17</td>\n",
       "      <td>10122.250000</td>\n",
       "      <td>3652.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.924206e+17</td>\n",
       "      <td>132810.000000</td>\n",
       "      <td>79515.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  favorite_count  retweet_count\n",
       "count  2.354000e+03     2354.000000    2354.000000\n",
       "mean   7.426978e+17     8080.968564    3164.797366\n",
       "std    6.852812e+16    11814.771334    5284.770364\n",
       "min    6.660209e+17        0.000000       0.000000\n",
       "25%    6.783975e+17     1415.000000     624.500000\n",
       "50%    7.194596e+17     3603.500000    1473.500000\n",
       "75%    7.993058e+17    10122.250000    3652.000000\n",
       "max    8.924206e+17   132810.000000   79515.000000"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_json.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for entry duplications\n",
    "tweet_json.id.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "749075273010798592    1\n",
       "741099773336379392    1\n",
       "798644042770751489    1\n",
       "825120256414846976    1\n",
       "769212283578875904    1\n",
       "700462010979500032    1\n",
       "780858289093574656    1\n",
       "699775878809702401    1\n",
       "880095782870896641    1\n",
       "760521673607086080    1\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_json.id.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                0\n",
       "favorite_count    0\n",
       "retweet_count     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing data/entries\n",
    "tweet_json.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290         0\n",
       "1293        2\n",
       "273         3\n",
       "341         3\n",
       "112         3\n",
       "        ...  \n",
       "816     52360\n",
       "1077    52360\n",
       "259     56625\n",
       "533     56625\n",
       "1037    79515\n",
       "Name: retweet_count, Length: 2354, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_json.retweet_count.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "484          0\n",
       "585          0\n",
       "164          0\n",
       "588          0\n",
       "909          0\n",
       "         ...  \n",
       "134     106827\n",
       "533     107015\n",
       "65      107956\n",
       "1037    131075\n",
       "412     132810\n",
       "Name: favorite_count, Length: 2354, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_json.favorite_count.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programmatic Assessment of Image Prediction Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2075 entries, 0 to 2074\n",
      "Data columns (total 12 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   tweet_id  2075 non-null   int64  \n",
      " 1   jpg_url   2075 non-null   object \n",
      " 2   img_num   2075 non-null   int64  \n",
      " 3   p1        2075 non-null   object \n",
      " 4   p1_conf   2075 non-null   float64\n",
      " 5   p1_dog    2075 non-null   bool   \n",
      " 6   p2        2075 non-null   object \n",
      " 7   p2_conf   2075 non-null   float64\n",
      " 8   p2_dog    2075 non-null   bool   \n",
      " 9   p3        2075 non-null   object \n",
      " 10  p3_conf   2075 non-null   float64\n",
      " 11  p3_dog    2075 non-null   bool   \n",
      "dtypes: bool(3), float64(3), int64(2), object(4)\n",
      "memory usage: 152.1+ KB\n"
     ]
    }
   ],
   "source": [
    "image_prediction.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>img_num</th>\n",
       "      <th>p1_conf</th>\n",
       "      <th>p2_conf</th>\n",
       "      <th>p3_conf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.075000e+03</td>\n",
       "      <td>2075.000000</td>\n",
       "      <td>2075.000000</td>\n",
       "      <td>2.075000e+03</td>\n",
       "      <td>2.075000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.384514e+17</td>\n",
       "      <td>1.203855</td>\n",
       "      <td>0.594548</td>\n",
       "      <td>1.345886e-01</td>\n",
       "      <td>6.032417e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.785203e+16</td>\n",
       "      <td>0.561875</td>\n",
       "      <td>0.271174</td>\n",
       "      <td>1.006657e-01</td>\n",
       "      <td>5.090593e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.660209e+17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.044333</td>\n",
       "      <td>1.011300e-08</td>\n",
       "      <td>1.740170e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.764835e+17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.364412</td>\n",
       "      <td>5.388625e-02</td>\n",
       "      <td>1.622240e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.119988e+17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.588230</td>\n",
       "      <td>1.181810e-01</td>\n",
       "      <td>4.944380e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.932034e+17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.843855</td>\n",
       "      <td>1.955655e-01</td>\n",
       "      <td>9.180755e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.924206e+17</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.880140e-01</td>\n",
       "      <td>2.734190e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tweet_id      img_num      p1_conf       p2_conf       p3_conf\n",
       "count  2.075000e+03  2075.000000  2075.000000  2.075000e+03  2.075000e+03\n",
       "mean   7.384514e+17     1.203855     0.594548  1.345886e-01  6.032417e-02\n",
       "std    6.785203e+16     0.561875     0.271174  1.006657e-01  5.090593e-02\n",
       "min    6.660209e+17     1.000000     0.044333  1.011300e-08  1.740170e-10\n",
       "25%    6.764835e+17     1.000000     0.364412  5.388625e-02  1.622240e-02\n",
       "50%    7.119988e+17     1.000000     0.588230  1.181810e-01  4.944380e-02\n",
       "75%    7.932034e+17     1.000000     0.843855  1.955655e-01  9.180755e-02\n",
       "max    8.924206e+17     4.000000     1.000000  4.880140e-01  2.734190e-01"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_prediction.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for entry duplications\n",
    "image_prediction.tweet_id.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for entry duplications\n",
    "image_prediction.jpg_url.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "685532292383666176    1\n",
       "826598365270007810    1\n",
       "692158366030913536    1\n",
       "714606013974974464    1\n",
       "715696743237730304    1\n",
       "776477788987613185    1\n",
       "772114945936949249    1\n",
       "699775878809702401    1\n",
       "780858289093574656    1\n",
       "700462010979500032    1\n",
       "Name: tweet_id, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_prediction.tweet_id.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id    0\n",
       "jpg_url     0\n",
       "img_num     0\n",
       "p1          0\n",
       "p1_conf     0\n",
       "p1_dog      0\n",
       "p2          0\n",
       "p2_conf     0\n",
       "p2_dog      0\n",
       "p3          0\n",
       "p3_conf     0\n",
       "p3_dog      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing data/entries\n",
    "image_prediction.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1561         Afghan_hound\n",
       "1855         Afghan_hound\n",
       "1458         Afghan_hound\n",
       "1804         Afghan_hound\n",
       "446     African_crocodile\n",
       "              ...        \n",
       "253           wood_rabbit\n",
       "1831         wooden_spoon\n",
       "932                  wool\n",
       "246                  wool\n",
       "297                 zebra\n",
       "Name: p1, Length: 2075, dtype: object"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_prediction.p1.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality Issues\n",
    "\n",
    "### Enhanced Archive Data Set  \n",
    "2,356 data entries in the dataset. The source column does not seem to add any value to differentiate tweets. It can be deleted.\n",
    "The \"text\" column has already been analyzed by Udacity; all needed information extracted into separate columns. It can be deleted or not merged into the final cleaned dateframe. Statistical analyses can be done on Dog \"stage\" and rating ratio (numerator/denominator).  \n",
    "\n",
    "1- Remove tweet entries prio to Agust 1, 2017.  \n",
    "\n",
    "2- Unoriginal tweets  \n",
    "- 78 entries of replies to status_id and user to remove\n",
    "- 181 entries of re-tweets that should be removed  \n",
    "\n",
    "3- Missing data  \n",
    "- missing expanded urls  \n",
    "\n",
    "4- 7 Duplicate entries and tweet_id. these may be indicating replies and retweets! Recheck for duplication after data cleaning.  \n",
    "5- Tweet_id is wrong; it should be a string not a number written in a scientific format.  \n",
    "\n",
    "6- Dtypes of rating numerators and denominators should be a float.  \n",
    "\n",
    "7- Dog Names:wrong or missing.\n",
    "   a- entries with one letter: e.g., \"a\"\n",
    "   b- no names (\"None\")\n",
    "   c- weird characters\n",
    "\n",
    "\n",
    "### tweet_json.txt  \n",
    "1- 2354 total entries --> 2 missing tweets!?  \n",
    "2- Column header of tweet_id is \"id\" unlike header's name in the archive data.  \n",
    "3- Dtype of \"id\" series is wrong; it is float. It should be a string.  \n",
    "\n",
    "\n",
    "### image_prediction.tsv  \n",
    "A total of 2.075 entries. \n",
    "\n",
    "1- Missing data.  \n",
    "2- Tweet_id format should not be numerical. It should be a string.  \n",
    "3- Dog breeds starting with lower and upper cases. Change all to lower case to be consistence.  \n",
    "4- Not all images are for dogs. Remove entries that do not correspond to dogs.  \n",
    "5- Extract/work only the predictions with the highest confidence.   \n",
    "6- Duplicated image url for different tweet_ids.  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Tidiness Issues  \n",
    "\n",
    "### All Data sets  \n",
    "1- Merging all datasets in one clean dataframe/one table with only important columns.  \n",
    "2- Tweet_id as separate entry in all dataframes.  \n",
    "3- Create a list of all columns and then find out duplicated columns\n",
    "\n",
    "### Enhanced Archive Data Set  \n",
    "1- Joining dog \"stages\" into one column instead of having 4 columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2356 entries, 0 to 2355\n",
      "Data columns (total 17 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   tweet_id                    2356 non-null   float64\n",
      " 1   in_reply_to_status_id       78 non-null     float64\n",
      " 2   in_reply_to_user_id         78 non-null     float64\n",
      " 3   timestamp                   2356 non-null   object \n",
      " 4   source                      2356 non-null   object \n",
      " 5   text                        2356 non-null   object \n",
      " 6   retweeted_status_id         181 non-null    float64\n",
      " 7   retweeted_status_user_id    181 non-null    float64\n",
      " 8   retweeted_status_timestamp  181 non-null    object \n",
      " 9   expanded_urls               2297 non-null   object \n",
      " 10  rating_numerator            2356 non-null   int64  \n",
      " 11  rating_denominator          2356 non-null   int64  \n",
      " 12  name                        2356 non-null   object \n",
      " 13  doggo                       2356 non-null   object \n",
      " 14  floofer                     2356 non-null   object \n",
      " 15  pupper                      2356 non-null   object \n",
      " 16  puppo                       2356 non-null   object \n",
      "dtypes: float64(5), int64(2), object(10)\n",
      "memory usage: 313.0+ KB\n"
     ]
    }
   ],
   "source": [
    "archive.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean = archive.copy()\n",
    "tweet_json_clean = tweet_json.copy()\n",
    "image_prediction_clean = image_prediction.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Quality Issues:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Remove Unoriginal Tweet Entries  \n",
    "\n",
    "#### Define  \n",
    "Remove all entries pertaining to replies to and retweeted tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean = archive_clean[archive_clean['in_reply_to_status_id'].isnull()]\n",
    "archive_clean = archive_clean[archive_clean['retweeted_status_id'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2097 entries, 0 to 2355\n",
      "Data columns (total 17 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   tweet_id                    2097 non-null   float64\n",
      " 1   in_reply_to_status_id       0 non-null      float64\n",
      " 2   in_reply_to_user_id         0 non-null      float64\n",
      " 3   timestamp                   2097 non-null   object \n",
      " 4   source                      2097 non-null   object \n",
      " 5   text                        2097 non-null   object \n",
      " 6   retweeted_status_id         0 non-null      float64\n",
      " 7   retweeted_status_user_id    0 non-null      float64\n",
      " 8   retweeted_status_timestamp  0 non-null      object \n",
      " 9   expanded_urls               2094 non-null   object \n",
      " 10  rating_numerator            2097 non-null   int64  \n",
      " 11  rating_denominator          2097 non-null   int64  \n",
      " 12  name                        2097 non-null   object \n",
      " 13  doggo                       2097 non-null   object \n",
      " 14  floofer                     2097 non-null   object \n",
      " 15  pupper                      2097 non-null   object \n",
      " 16  puppo                       2097 non-null   object \n",
      "dtypes: float64(5), int64(2), object(10)\n",
      "memory usage: 294.9+ KB\n"
     ]
    }
   ],
   "source": [
    "archive_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Remove Duplicates   \n",
    "\n",
    "#### Define  \n",
    "After removing unoriginal tweets, check for tweet_id duplicates and remove them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for entry duplications\n",
    "archive_clean.tweet_id.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.751470e+17    2\n",
       "7.184600e+17    1\n",
       "6.681420e+17    1\n",
       "6.722640e+17    1\n",
       "6.709960e+17    1\n",
       "               ..\n",
       "8.892790e+17    1\n",
       "6.729950e+17    1\n",
       "8.918150e+17    1\n",
       "7.783830e+17    1\n",
       "7.787650e+17    1\n",
       "Name: tweet_id, Length: 2096, dtype: int64"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive_clean.tweet_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean.tweet_id.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for entry duplications\n",
    "archive_clean.tweet_id.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- Remove Rows with Missing Data (expanded URLs, )   \n",
    "\n",
    "#### Define  \n",
    "Remove rows that have missing \"expanded_urls'.  \n",
    "archive_clean.info() indicates that there are still 3 entries with no expanded url specified. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean.expanded_urls.dropna( inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for entry duplications\n",
    "archive_clean.expanded_urls.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the image-prediction dataframe has series with missing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for entry duplications\n",
    "image_prediction_clean.jpg_url.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4- Change Tweet ID Formats  \n",
    "\n",
    "#### Define  \n",
    "Change the tweet_id format to string instead of it being a flloat written in scientific format in all dataframes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean.tweet_id = archive_clean.tweet_id.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_json_clean.id = tweet_json_clean.id.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_prediction_clean.tweet_id = image_prediction_clean.tweet_id.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean.tweet_id.dtype;\n",
    "tweet_json_clean.id.dtype;\n",
    "image_prediction_clean.tweet_id.dtype;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "#archive_clean.info();\n",
    "#tweet_json.info();\n",
    "#image_prediction.info();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5- Change Rating (Numerator, Denominator) Formats  \n",
    "\n",
    "#### Define  \n",
    "Change the format of the rating entries to float.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean.rating_numerator = archive_clean.rating_numerator.astype(float)\n",
    "archive_clean.rating_denominator = archive_clean.rating_denominator.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive_clean.rating_numerator.dtype;\n",
    "archive_clean.rating_denominator.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6- Rename Series Header  \n",
    "\n",
    "#### Define  \n",
    "Rename the tweet id column in the tweet_json dataframe. Change header form 'id' to 'tweet_id'.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_json_clean.rename(index=str, columns={'id':'tweet_id'}, inplace=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2354 entries, 0 to 2353\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   tweet_id        2354 non-null   object\n",
      " 1   favorite_count  2354 non-null   int64 \n",
      " 2   retweet_count   2354 non-null   int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 73.6+ KB\n"
     ]
    }
   ],
   "source": [
    "tweet_json_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7- Dog Breed Starting Lower and Upper Case  \n",
    "\n",
    "#### Define  \n",
    "The predicted dog breeds in the image_prediction file start with either lower or upper case.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_prediction_clean.p1 = image_prediction_clean.p1.str.lower()\n",
    "image_prediction_clean.p2 = image_prediction_clean.p2.str.lower()\n",
    "image_prediction_clean.p3 = image_prediction_clean.p3.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_prediction_clean.head(10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8- Remove Image Entries Not Showing Dogs   \n",
    "\n",
    "#### Define  \n",
    "The iamge_prediction file has entries where the images are not indicating a dog. Remove images not showing dogs in the algorithim's #1 prediction (p1 and p1_dog) from dataframe.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_prediction_clean = image_prediction_clean.loc[image_prediction_clean.p1_dog, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_prediction_clean = image_prediction_clean[image_prediction_clean['p1_dog'] == 'FALSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1532 entries, 0 to 2073\n",
      "Data columns (total 12 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   tweet_id  1532 non-null   object \n",
      " 1   jpg_url   1532 non-null   object \n",
      " 2   img_num   1532 non-null   int64  \n",
      " 3   p1        1532 non-null   object \n",
      " 4   p1_conf   1532 non-null   float64\n",
      " 5   p1_dog    1532 non-null   bool   \n",
      " 6   p2        1532 non-null   object \n",
      " 7   p2_conf   1532 non-null   float64\n",
      " 8   p2_dog    1532 non-null   bool   \n",
      " 9   p3        1532 non-null   object \n",
      " 10  p3_conf   1532 non-null   float64\n",
      " 11  p3_dog    1532 non-null   bool   \n",
      "dtypes: bool(3), float64(3), int64(1), object(5)\n",
      "memory usage: 124.2+ KB\n"
     ]
    }
   ],
   "source": [
    "image_prediction_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1532"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_prediction_clean.p1_dog.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for entry duplications\n",
    "image_prediction_clean.jpg_url.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even after removing imagees not showing dogs, there are still 52 duplicated image URLs in the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for entry duplications\n",
    "image_prediction_clean.tweet_id.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check for entry duplications\n",
    "#image_prediction_clean.jpg_url.duplicated().index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9- Correct Dog Names   \n",
    "\n",
    "#### Define  \n",
    "There are some tweets where the dog name is either 'None' or weird character/adjective ('a' or 'an', 'quite', 'the','such'). Remove these entries from data set if needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None          603\n",
       "a              55\n",
       "Charlie        11\n",
       "Lucy           11\n",
       "Oliver         10\n",
       "             ... \n",
       "Nimbus          1\n",
       "officially      1\n",
       "Chevy           1\n",
       "Kenny           1\n",
       "Perry           1\n",
       "Name: name, Length: 955, dtype: int64"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive_clean.name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603\n",
      "55\n",
      "6\n",
      "8\n",
      "1\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "wrong_name = ['None','a','an','the','such','quite']\n",
    "for i in wrong_name:\n",
    "    len(archive_clean[archive_clean['name'] == i])\n",
    "    print (len(archive_clean[archive_clean['name'] == i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_nobadnames = archive_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_name = ['None','a','an','the','such','quite']\n",
    "for i in wrong_name:\n",
    "    archive_nobadnames.drop(archive_nobadnames[archive_nobadnames['name'] == i].index, inplace = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Charlie       11\n",
       "Lucy          11\n",
       "Oliver        10\n",
       "Cooper        10\n",
       "Tucker         9\n",
       "              ..\n",
       "officially     1\n",
       "Chevy          1\n",
       "Kenny          1\n",
       "Brandonald     1\n",
       "Perry          1\n",
       "Name: name, Length: 949, dtype: int64"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive_nobadnames.name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BAD.  this leaves only rows with dog name = 'a'.\n",
    "#archive_clean = archive_clean[archive_clean['name'] == 'a']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Tidiness Issues:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Combine Dog Stage Columns   \n",
    "\n",
    "#### Define  \n",
    "In the twitter_archive_enhanced file, the dog stage data occur, needlessly, in 4 columns. We need to merge all 4 columns into 1.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code  \n",
    "\n",
    "Hint obtained from a mentor's answer in Udacity help page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all 'None' entries for dog stage with '' \n",
    "archive_clean.doggo.replace('None', '', inplace=True)\n",
    "archive_clean.floofer.replace('None', '', inplace=True)\n",
    "archive_clean.pupper.replace('None', '', inplace=True)\n",
    "archive_clean.puppo.replace('None', '', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining all dog stage columns in a new column called 'stage'\n",
    "archive_clean['stage'] = archive_clean.doggo + archive_clean.floofer + archive_clean.pupper + archive_clean.puppo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                1761\n",
       "pupper           221\n",
       "doggo             72\n",
       "puppo             23\n",
       "doggopupper        9\n",
       "floofer            9\n",
       "doggofloofer       1\n",
       "doggopuppo         1\n",
       "Name: stage, dtype: int64"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show some statistics on the most abumdant doge stage identified in the data\n",
    "archive_clean.stage.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "# further cleaning in case thre are entries with double stages indicated (not the case in our cleaned archive dataframe)\n",
    "archive_clean.loc[archive_clean.stage == 'doggopupper', 'stage'] = 'doggo,pupper'\n",
    "archive_clean.loc[archive_clean.stage == 'doggopuppo', 'stage'] = 'doggo,puppo'\n",
    "archive_clean.loc[archive_clean.stage == 'doggofloofer', 'stage'] = 'doggo,floofer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean.loc[archive_clean.stage == '', 'stage'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unneeded columns from the dataframe\n",
    "archive_clean.drop(['doggo', 'floofer', 'pupper', 'puppo'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pupper           221\n",
       "doggo             72\n",
       "puppo             23\n",
       "doggo,pupper       9\n",
       "floofer            9\n",
       "doggo,floofer      1\n",
       "doggo,puppo        1\n",
       "Name: stage, dtype: int64"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive_clean.stage.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "      <th>retweeted_status_user_id</th>\n",
       "      <th>retweeted_status_timestamp</th>\n",
       "      <th>expanded_urls</th>\n",
       "      <th>rating_numerator</th>\n",
       "      <th>rating_denominator</th>\n",
       "      <th>name</th>\n",
       "      <th>stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.92421e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-01 16:23:56 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Phineas. He's a mystical boy. Only eve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/892420643...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Phineas</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.92177e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-01 00:17:27 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Tilly. She's just checking pup on you....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/892177421...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Tilly</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tweet_id  in_reply_to_status_id  in_reply_to_user_id  \\\n",
       "0  8.92421e+17                    NaN                  NaN   \n",
       "1  8.92177e+17                    NaN                  NaN   \n",
       "\n",
       "                   timestamp  \\\n",
       "0  2017-08-01 16:23:56 +0000   \n",
       "1  2017-08-01 00:17:27 +0000   \n",
       "\n",
       "                                              source  \\\n",
       "0  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "1  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "\n",
       "                                                text  retweeted_status_id  \\\n",
       "0  This is Phineas. He's a mystical boy. Only eve...                  NaN   \n",
       "1  This is Tilly. She's just checking pup on you....                  NaN   \n",
       "\n",
       "   retweeted_status_user_id retweeted_status_timestamp  \\\n",
       "0                       NaN                        NaN   \n",
       "1                       NaN                        NaN   \n",
       "\n",
       "                                       expanded_urls  rating_numerator  \\\n",
       "0  https://twitter.com/dog_rates/status/892420643...              13.0   \n",
       "1  https://twitter.com/dog_rates/status/892177421...              13.0   \n",
       "\n",
       "   rating_denominator     name stage  \n",
       "0                10.0  Phineas   NaN  \n",
       "1                10.0    Tilly   NaN  "
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive_clean.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2097 entries, 0 to 2355\n",
      "Data columns (total 14 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   tweet_id                    2096 non-null   object \n",
      " 1   in_reply_to_status_id       0 non-null      float64\n",
      " 2   in_reply_to_user_id         0 non-null      float64\n",
      " 3   timestamp                   2097 non-null   object \n",
      " 4   source                      2097 non-null   object \n",
      " 5   text                        2097 non-null   object \n",
      " 6   retweeted_status_id         0 non-null      float64\n",
      " 7   retweeted_status_user_id    0 non-null      float64\n",
      " 8   retweeted_status_timestamp  0 non-null      object \n",
      " 9   expanded_urls               2094 non-null   object \n",
      " 10  rating_numerator            2097 non-null   float64\n",
      " 11  rating_denominator          2097 non-null   float64\n",
      " 12  name                        2097 non-null   object \n",
      " 13  stage                       336 non-null    object \n",
      "dtypes: float64(6), object(8)\n",
      "memory usage: 245.7+ KB\n"
     ]
    }
   ],
   "source": [
    "archive_clean.info();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Merge Dataframes  \n",
    "\n",
    "Before moving to analyses and visualization:  \n",
    "1- Uneeded columns will be dropped from dataframe (twitter_enhanced_archinve and image-prediction). Only 3 columns ('tweet_id', 'retweet_count', and 'favorite_count'will be useful from the tweet_json file.  \n",
    "\n",
    "2- All dataframes will be merged into one final dataframe.  \n",
    "\n",
    "#### 2a - Define  \n",
    "Drop cloumns from archive_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2a- Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean2 = archive_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2097 entries, 0 to 2355\n",
      "Data columns (total 14 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   tweet_id                    2096 non-null   object \n",
      " 1   in_reply_to_status_id       0 non-null      float64\n",
      " 2   in_reply_to_user_id         0 non-null      float64\n",
      " 3   timestamp                   2097 non-null   object \n",
      " 4   source                      2097 non-null   object \n",
      " 5   text                        2097 non-null   object \n",
      " 6   retweeted_status_id         0 non-null      float64\n",
      " 7   retweeted_status_user_id    0 non-null      float64\n",
      " 8   retweeted_status_timestamp  0 non-null      object \n",
      " 9   expanded_urls               2094 non-null   object \n",
      " 10  rating_numerator            2097 non-null   float64\n",
      " 11  rating_denominator          2097 non-null   float64\n",
      " 12  name                        2097 non-null   object \n",
      " 13  stage                       336 non-null    object \n",
      "dtypes: float64(6), object(8)\n",
      "memory usage: 245.7+ KB\n"
     ]
    }
   ],
   "source": [
    "archive_clean2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unneeded columns from the archive dataframe \n",
    "archive_clean2.drop(['in_reply_to_status_id', 'in_reply_to_user_id', 'source', 'text'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unneeded columns from the archive dataframe \n",
    "archive_clean2.drop(['retweeted_status_id','retweeted_status_user_id','retweeted_status_timestamp'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2a- Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2097 entries, 0 to 2355\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   tweet_id            2096 non-null   object \n",
      " 1   timestamp           2097 non-null   object \n",
      " 2   expanded_urls       2094 non-null   object \n",
      " 3   rating_numerator    2097 non-null   float64\n",
      " 4   rating_denominator  2097 non-null   float64\n",
      " 5   name                2097 non-null   object \n",
      " 6   stage               336 non-null    object \n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 131.1+ KB\n"
     ]
    }
   ],
   "source": [
    "archive_clean2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2b - Define  \n",
    "Drop uneeded cloumns from image-prediction. Keep only predictions with high confidence (p1, p1_dog). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1532 entries, 0 to 2073\n",
      "Data columns (total 12 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   tweet_id  1532 non-null   object \n",
      " 1   jpg_url   1532 non-null   object \n",
      " 2   img_num   1532 non-null   int64  \n",
      " 3   p1        1532 non-null   object \n",
      " 4   p1_conf   1532 non-null   float64\n",
      " 5   p1_dog    1532 non-null   bool   \n",
      " 6   p2        1532 non-null   object \n",
      " 7   p2_conf   1532 non-null   float64\n",
      " 8   p2_dog    1532 non-null   bool   \n",
      " 9   p3        1532 non-null   object \n",
      " 10  p3_conf   1532 non-null   float64\n",
      " 11  p3_dog    1532 non-null   bool   \n",
      "dtypes: bool(3), float64(3), int64(1), object(5)\n",
      "memory usage: 124.2+ KB\n"
     ]
    }
   ],
   "source": [
    "image_prediction_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2b- Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_prediction_clean2 = image_prediction_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unneeded columns from the archive dataframe \n",
    "image_prediction_clean2.drop(['p2', 'p3', 'p2_conf', 'p3_conf', 'p1_dog', 'p2_dog', 'p3_dog'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2b- Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1532 entries, 0 to 2073\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   tweet_id  1532 non-null   object \n",
      " 1   jpg_url   1532 non-null   object \n",
      " 2   img_num   1532 non-null   int64  \n",
      " 3   p1        1532 non-null   object \n",
      " 4   p1_conf   1532 non-null   float64\n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 71.8+ KB\n"
     ]
    }
   ],
   "source": [
    "image_prediction_clean2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the number of tweet_id in each df to see how to merge the dfs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2354 entries, 0 to 2353\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   tweet_id        2354 non-null   object\n",
      " 1   favorite_count  2354 non-null   int64 \n",
      " 2   retweet_count   2354 non-null   int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 73.6+ KB\n"
     ]
    }
   ],
   "source": [
    "tweet_json_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2097 entries, 0 to 2355\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   tweet_id            2096 non-null   object \n",
      " 1   timestamp           2097 non-null   object \n",
      " 2   expanded_urls       2094 non-null   object \n",
      " 3   rating_numerator    2097 non-null   float64\n",
      " 4   rating_denominator  2097 non-null   float64\n",
      " 5   name                2097 non-null   object \n",
      " 6   stage               336 non-null    object \n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 131.1+ KB\n"
     ]
    }
   ],
   "source": [
    "archive_clean2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2c - Define  \n",
    "Merge dataframes into one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2c- Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concat is not the right thing to do as dfs are added on top of each others. merge is a better choice:\n",
    "referecen 'https://realpython.com/pandas-merge-join-and-concat/#how-to-merge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_final1 = pd.concat([archive_clean2,image_prediction_clean2,tweet_json_clean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1532 entries, 0 to 2073\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   tweet_id  1532 non-null   int64  \n",
      " 1   jpg_url   1532 non-null   object \n",
      " 2   img_num   1532 non-null   int64  \n",
      " 3   p1        1532 non-null   object \n",
      " 4   p1_conf   1532 non-null   float64\n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 71.8+ KB\n"
     ]
    }
   ],
   "source": [
    "image_prediction_clean2['tweet_id'] = pd.to_numeric(image_prediction_clean2['tweet_id'], errors='coerce')\n",
    "image_prediction_clean2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2354 entries, 0 to 2353\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype\n",
      "---  ------          --------------  -----\n",
      " 0   tweet_id        2354 non-null   int64\n",
      " 1   favorite_count  2354 non-null   int64\n",
      " 2   retweet_count   2354 non-null   int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 73.6+ KB\n"
     ]
    }
   ],
   "source": [
    "tweet_json_clean['tweet_id'] = pd.to_numeric(tweet_json_clean['tweet_id'], errors='coerce')\n",
    "tweet_json_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2097 entries, 0 to 2355\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   tweet_id            2096 non-null   float64\n",
      " 1   timestamp           2097 non-null   object \n",
      " 2   expanded_urls       2094 non-null   object \n",
      " 3   rating_numerator    2097 non-null   float64\n",
      " 4   rating_denominator  2097 non-null   float64\n",
      " 5   name                2097 non-null   object \n",
      " 6   stage               336 non-null    object \n",
      "dtypes: float64(3), object(4)\n",
      "memory usage: 131.1+ KB\n"
     ]
    }
   ],
   "source": [
    "archive_clean2['tweet_id'] = pd.to_numeric(archive_clean2['tweet_id'], errors='coerce')\n",
    "#archive_clean2.tweet_id = archive_clean2.tweet_id.astype(int)\n",
    "archive_clean2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2097 entries, 0 to 2355\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   tweet_id            2097 non-null   object \n",
      " 1   timestamp           2097 non-null   object \n",
      " 2   expanded_urls       2094 non-null   object \n",
      " 3   rating_numerator    2097 non-null   float64\n",
      " 4   rating_denominator  2097 non-null   float64\n",
      " 5   name                2097 non-null   object \n",
      " 6   stage               336 non-null    object \n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 131.1+ KB\n"
     ]
    }
   ],
   "source": [
    "archive_clean2.tweet_id = archive_clean.tweet_id.astype(str)\n",
    "archive_clean2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2097 entries, 0 to 2355\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   tweet_id            2096 non-null   float64\n",
      " 1   timestamp           2097 non-null   object \n",
      " 2   expanded_urls       2094 non-null   object \n",
      " 3   rating_numerator    2097 non-null   float64\n",
      " 4   rating_denominator  2097 non-null   float64\n",
      " 5   name                2097 non-null   object \n",
      " 6   stage               336 non-null    object \n",
      "dtypes: float64(3), object(4)\n",
      "memory usage: 131.1+ KB\n"
     ]
    }
   ],
   "source": [
    "archive_clean2['tweet_id'] = pd.to_numeric(archive_clean2['tweet_id'], errors='coerce')\n",
    "archive_clean2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean2.tweet_id = archive_clean2.tweet_id.astype(str)\n",
    "\n",
    "archive_clean2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean2.to_csv('archive_clean2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_final2 = pd.merge(archive_clean2, image_prediction_clean2, how='inner', on=\"tweet_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 0 entries\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   tweet_id            0 non-null      float64\n",
      " 1   timestamp           0 non-null      object \n",
      " 2   expanded_urls       0 non-null      object \n",
      " 3   rating_numerator    0 non-null      float64\n",
      " 4   rating_denominator  0 non-null      float64\n",
      " 5   name                0 non-null      object \n",
      " 6   stage               0 non-null      object \n",
      " 7   jpg_url             0 non-null      object \n",
      " 8   img_num             0 non-null      int64  \n",
      " 9   p1                  0 non-null      object \n",
      " 10  p1_conf             0 non-null      float64\n",
      "dtypes: float64(4), int64(1), object(6)\n",
      "memory usage: 0.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "tweets_final2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_final2 = pd.concat([archive_clean2,image_prediction_clean2,tweet_json_clean])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyses and Visualization  \n",
    "\n",
    "Storing, Analyzing, and Visualizing Data for this Project\n",
    "Store the clean DataFrame(s) in a CSV file with the main one named twitter_archive_master.csv. If additional files exist because multiple tables are required for tidiness, name these files appropriately. Additionally, you may store the cleaned data in a SQLite database (which is to be submitted as well if you do).\n",
    "\n",
    "Analyze and visualize your wrangled data in your wrangle_act.ipynb Jupyter Notebook. At least three (3) insights and one (1) visualization must be produced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store Cleaned Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_final.to_csv('dog_tweet_df_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary Insights!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tweets favorited by most users?\n",
    "\n",
    "- Common dog names  \n",
    "\n",
    "- easily identified dog breeds: What are the most common breeds found by the neural network?  \n",
    "\n",
    "- correlating breed to ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##If you want to see only the rows that contains the NaN values you could do:\n",
    "#data_frame[data_frame.iloc[:, insert column number here]=='NaN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for specific entry\n",
    "archive[archive.series1 == 'entry'].series2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(archive)\n",
    "#archive.sample(5)\n",
    "#patients[patients.address.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename column 'id' to 'tweet_id'\n",
    "tweet_likes.rename(columns={'id':'tweet_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reporting for this Project\n",
    "Create a 300-600 word written report called wrangle_report.pdf or wrangle_report.html that briefly describes your wrangling efforts. This is to be framed as an internal document.\n",
    "\n",
    "Create a 250-word-minimum written report called act_report.pdf or act_report.html that communicates the insights and displays the visualization(s) produced from your wrangled data. This is to be framed as an external document, like a blog post or magazine article, for example.\n",
    "\n",
    "Both of these documents can be created in separate Jupyter Notebooks using the Markdown functionality of Jupyter Notebooks, then downloading those notebooks as PDF files or HTML files (see image below). You might prefer to use a word processor like Google Docs or Microsoft Word, however.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "•\ttwitter_archive_master.csv: combined and cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
